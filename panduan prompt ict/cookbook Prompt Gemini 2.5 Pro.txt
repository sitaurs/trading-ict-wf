Memaksimalkan Gemini 2.5 Pro: Panduan Developer untuk 
Rekayasa Prompt Tingkat Lanjut dan Optimalisasi API 
 

 
Bagian I: Fondasi Arsitektur Gemini 2.5 Pro 
 
Untuk memaksimalkan kapabilitas Gemini 2.5 Pro API, pemahaman mendalam 
mengenai arsitektur dasarnya adalah sebuah keharusan. Bagian ini akan menguraikan 
konsep fundamental yang membedakan model ini, mulai dari arsitektur "berpikir" yang 
revolusioner hingga detail praktis dalam mengonfigurasi lingkungan pengembangan 
dan menstrukturkan panggilan API. 

 

1.1. Pergeseran Paradigma dalam Penalaran: Model "Berpikir" 
 

Gemini 2.5 Pro menandai sebuah evolusi signifikan, bukan sekadar pembaruan 
inkremental, dengan memperkenalkan arsitektur sebagai "model berpikir" (thinking 
model).1 Kapabilitas ini merujuk pada proses penalaran internal yang dilakukan model 
sebelum menghasilkan respons, sebuah fitur yang dirancang secara natif untuk 
meningkatkan performa dan akurasi pada tugas-tugas kompleks yang memerlukan 
perencanaan multi-langkah, seperti 

coding tingkat lanjut, matematika, dan analisis data.1 

Secara teknis, kemampuan ini merupakan hasil dari kombinasi model dasar yang 
ditingkatkan secara substansial dengan teknik post-training yang lebih canggih, 
dibangun di atas penelitian sebelumnya dalam reinforcement learning dan 
Chain-of-Thought (CoT) prompting.3 Model ini dibangun di atas arsitektur 

sparse Mixture-of-Experts (MoE), yang memungkinkan pemisahan antara kapasitas 
total model dengan biaya komputasi per token, sehingga mencapai efisiensi yang 



lebih tinggi.5 

Implikasi paling mendasar bagi para developer adalah pergeseran peran. Sebelumnya, 
developer harus secara eksplisit "memaksa" model untuk bernalar melalui rekayasa 
prompt yang rumit. Kini, dengan kemampuan penalaran yang sudah menjadi bagian 
inheren dari model, tugas developer beralih menjadi "membimbing dan mengontrol" 
proses tersebut. Fokusnya tidak lagi pada bagaimana cara menulis prompt CoT 
manual, melainkan pada bagaimana memanfaatkan parameter API untuk mengelola 
proses penalaran internal ini secara efektif dan efisien.1 Abstraksi penalaran ini 
menyederhanakan logika inti yang diperlukan untuk membangun sistem agentik, 
karena agen kini dapat mengandalkan kapabilitas perencanaan internal model 
alih-alih harus mengelola serangkaian 

prompt berantai yang kompleks. 

 

1.2. Akses API dan Konfigurasi Lingkungan 
 

Akses ke Gemini 2.5 Pro API difasilitasi melalui dua jalur utama yang melayani 
kebutuhan berbeda: Google AI Studio dan Vertex AI.2 Google AI Studio sangat ideal 
untuk 

prototyping cepat, pengujian prompt, dan pengembangan skala kecil, menawarkan 
antarmuka yang ramah pengguna dan akses gratis untuk memulai.7 Sebaliknya, Vertex 
AI dirancang untuk aplikasi skala perusahaan yang menuntut skalabilitas, keamanan, 
dan integrasi yang lebih dalam dengan ekosistem Google Cloud.2 

Autentikasi 
Langkah pertama untuk berinteraksi dengan API adalah autentikasi. Untuk Google AI Studio, 
proses ini melibatkan pembuatan Kunci API (API Key).7 Praktik terbaik keamanan yang sangat 
dianjurkan adalah menyimpan kunci ini sebagai variabel lingkungan (misalnya, 
GEMINI_API_KEY atau GOOGLE_API_KEY) dan tidak pernah menyematkannya secara 
langsung di dalam kode (hardcoding).10 Untuk lingkungan Vertex AI, metode 
autentikasi yang direkomendasikan untuk pengembangan lokal adalah dengan 
menyiapkan 

Application Default Credentials (ADC).2 

Instalasi dan Inisialisasi SDK 



Google menyediakan Software Development Kits (SDK) untuk berbagai bahasa pemrograman, 
dengan Python menjadi yang paling umum digunakan. Sangat penting untuk menginstal dan 
menggunakan SDK google-genai yang baru, karena SDK ini mendukung fitur-fitur terbaru 
yang tidak tersedia di paket lama google-generativeai.12 
Berikut adalah contoh instalasi dan inisialisasi SDK Python: 
1.​ Instalasi Pustaka:​

Bash​
pip install google-genai​
​
9 

2.​ Inisialisasi Klien:​
Python​
import google.generativeai as genai​
import os​
​
# Konfigurasi kunci API dari variabel lingkungan​
genai.configure(api_key=os.environ)​
​
# Buat instance model​
model = genai.GenerativeModel('gemini-2.5-pro')​
​
9 

Selain Python, SDK juga tersedia untuk JavaScript/TypeScript, Go, dan Java, 
memungkinkan integrasi yang luas di berbagai platform.13 

Interaksi REST API 
Untuk lingkungan di mana SDK tidak tersedia atau untuk tujuan debugging tingkat rendah, 
interaksi langsung dengan REST API dapat dilakukan. Berikut adalah contoh panggilan 
menggunakan curl ke endpoint generateContent: 

 

Bash 
 
 
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent" \​
-H "x-goog-api-key: $GEMINI_API_KEY" \​
-H 'Content-Type: application/json' \​
-X POST \​
-d '{​
  "contents": [​



    {​
      "parts": [​
        {​
          "text": "Jelaskan konsep Lubang Hitam secara sederhana."​
        }​
      ]​
    }​
  ]​
}'​
 
4 

 

1.3. Anatomi Permintaan API 
 

Memahami struktur badan permintaan (request body) JSON adalah kunci untuk 
memanfaatkan seluruh spektrum kemampuan Gemini 2.5 Pro. Setiap panggilan ke 
endpoint models/gemini-2.5-pro:generateContent terdiri dari beberapa objek tingkat 
atas yang krusial.4 

●​ contents: Ini adalah objek inti yang berisi prompt itu sendiri. Objek ini berupa 
sebuah array, yang dirancang untuk mendukung input multimodal. Setiap elemen 
dalam array ini mewakili satu giliran dalam percakapan dan berisi array parts. 
Setiap part dapat berisi text untuk input teks, inlineData untuk gambar yang 
dikodekan dalam base64, atau fileData untuk media yang lebih besar seperti 
audio dan video yang diunggah melalui File API.2 

●​ generationConfig: Objek ini berfungsi sebagai panel kontrol utama untuk 
mengatur aspek kreatif dan gaya dari respons yang dihasilkan. Di sinilah 
parameter seperti temperature, topP, dan maxOutputTokens didefinisikan. Objek 
ini akan dibahas secara mendalam di Bagian II.4 

●​ safetySettings: Objek ini memungkinkan developer untuk mengonfigurasi filter 
konten yang bertanggung jawab, menyesuaikan ambang batas untuk berbagai 
kategori bahaya guna memastikan output yang aman dan sesuai dengan 
kebijakan aplikasi.17 

●​ tools & toolConfig: Objek-objek ini adalah fondasi untuk perilaku agentik. tools 
digunakan untuk mendeklarasikan fungsi eksternal (function calling) atau 
mengaktifkan alat bawaan seperti eksekusi kode (code execution). toolConfig 
menyediakan konfigurasi lebih lanjut untuk alat-alat tersebut.14 Kemampuan ini 
akan dieksplorasi di Bagian III. 

●​ system_instruction: Objek ini digunakan untuk memberikan instruksi tingkat tinggi 



yang persisten atau untuk menetapkan persona yang harus diadopsi oleh model 
selama percakapan. Instruksi ini memengaruhi semua giliran dalam sesi tersebut, 
memberikan konteks yang stabil dan konsisten.17 

 

Bagian II: Menguasai Kontrol Generasi dan Penalaran 
 
Setelah memahami struktur dasar permintaan API, langkah selanjutnya adalah 
menguasai parameter-parameter yang memberikan kontrol granular atas perilaku 
model. Bagian ini akan menyelami generationConfig untuk membentuk gaya output 
dan thinkingConfig untuk mengendalikan mesin penalaran inti Gemini 2.5 Pro. 

 

2.1. Parameter Generasi Inti (generationConfig) 
 

Objek generationConfig adalah perangkat utama bagi developer untuk membentuk 
"tekstur" dari respons model. Objek ini mengontrol tingkat keacakan, panjang, dan 
kondisi penghentian output, yang secara langsung memengaruhi kreativitas, 
keterprediksian, dan efisiensi biaya.21 

Analisis Mendalam Parameter 
●​ temperature: Mengontrol keacakan dalam pemilihan token. Rentangnya adalah 

dari 0.0 (paling deterministik) hingga 2.0 (paling kreatif), dengan nilai default 
1.0.18 Nilai yang rendah (misalnya,​
0.2) sangat direkomendasikan untuk tugas-tugas yang membutuhkan akurasi 
faktual, seperti pembuatan kode, pemecahan masalah matematika, atau tugas 
penalaran. Sebaliknya, nilai yang lebih tinggi (misalnya, 1.5 hingga 2.0) cocok 
untuk tugas-tugas kreatif seperti penulisan cerita, brainstorming, atau 
pembuatan konten yang beragam.24 

●​ topP: Dikenal sebagai nucleus sampling, parameter ini merupakan alternatif dari 
temperature untuk mengontrol keacakan. Rentangnya adalah 0.0 hingga 1.0, 
dengan default 0.95.18 Model akan mempertimbangkan token dari yang paling 
mungkin hingga yang paling tidak mungkin sampai jumlah probabilitas 
kumulatifnya mencapai nilai​
topP. Nilai yang lebih rendah akan menghasilkan output yang lebih fokus dan 



kurang acak.22 

●​ topK: Membatasi pemilihan token hanya pada K token yang paling mungkin. Untuk 
Gemini 2.5 Pro di Vertex AI, nilai ini ditetapkan secara permanen pada 64 dan 
tidak dapat diubah.18 

●​ candidateCount: Menentukan jumlah variasi respons yang akan dihasilkan untuk 
satu prompt. Rentangnya adalah 1 hingga 8, dengan default 1.18 Fitur ini sangat 
berguna untuk pengujian A/B pada​
prompt yang berbeda atau untuk memberikan beberapa pilihan kepada pengguna 
akhir. 

●​ maxOutputTokens: Menetapkan batas maksimum jumlah token yang dapat 
dihasilkan dalam respons. Di Vertex AI, nilai default dan maksimumnya adalah 
65,536.2 Mengatur parameter ini sangat penting untuk mengelola biaya API dan 
mencegah respons yang terpotong secara tiba-tiba, terutama saat menangani 
tugas yang berpotensi menghasilkan output panjang.22 

●​ stopSequences: Berupa sebuah array yang dapat berisi hingga 5 urutan karakter 
(string). Ketika model menghasilkan salah satu dari urutan ini, proses generasi 
akan segera berhenti. Urutan penghentian itu sendiri tidak akan disertakan dalam 
output akhir. Parameter ini sangat esensial untuk mengontrol format output 
secara presisi, misalnya, menghentikan generasi setelah tag penutup HTML atau 
JSON, atau untuk membuat alur interaksi yang dikustomisasi.23 

●​ presence_penalty & frequency_penalty: Parameter ini, yang sering tersedia 
melalui endpoint yang kompatibel dengan OpenAI di Vertex AI, memberikan 
kontrol lebih lanjut untuk mengurangi repetisi. presence_penalty memberikan 
penalti pada token yang sudah muncul dalam teks sejauh ini, mendorong model 
untuk memperkenalkan topik baru. frequency_penalty memberikan penalti 
berdasarkan seberapa sering token tersebut muncul, mengurangi kemungkinan 
pengulangan frasa yang sama persis. Keduanya memiliki rentang dari -2.0 hingga 
2.0.28 

Tabel 1: Referensi Parameter generationConfig 

Parameter Deskripsi Tipe Data Rentang Nilai Default Kasus 
Penggunaan 
Utama 

temperature Mengontrol Float 0.0 - 2.0 1.0 Menyesuaika
keacakan n antara 
output. Nilai respons 
lebih tinggi faktual 

(rendah) dan 



lebih kreatif. kreatif 
(tinggi). 

topP Nucleus Float 0.0 - 1.0 0.95 Alternatif 
sampling. untuk 
Memilih dari temperature 
token dalam 
dengan mengontrol 
probabilitas keacakan. 
kumulatif 
tertinggi. 

topK Membatasi Integer Tetap 64 (di Vertex Ditetapkan 
sampling AI) oleh sistem 
pada K token untuk 
yang paling menjaga 
mungkin. kualitas 

dasar. 

candidateCo Jumlah Integer 1 - 8 1 Menghasilka
unt kandidat n beberapa 

respons opsi respons 
yang akan untuk 
dihasilkan. perbandinga

n atau 
pilihan 
pengguna. 

maxOutputT Batas Integer 1 - 65,536 65,536 Mengontrol 
okens maksimum panjang 

token untuk output, 
output yang biaya, dan 
dihasilkan. latensi. 

stopSequenc Kumpulan Array of Hingga 5 Kosong Memastikan 
es string yang Strings string format 

akan output yang 
menghentika terstruktur 
n generasi dan 
saat ditemui. menghentika

n generasi 
pada titik 
tertentu. 



presence_pe Memberi Float -2.0 - 2.0 0.0 Mengurangi 
nalty penalti pada repetisi topik 

token yang dan 
sudah ada, meningkatka
mendorong n keragaman 
topik baru. konten. 

frequency_p Memberi Float -2.0 - 2.0 0.0 Mencegah 
enalty penalti pada model 

token mengulang 
berdasarkan frasa atau 
frekuensinya kalimat yang 
, mengurangi sama persis. 
pengulangan 
kata. 

 

2.2. Memanfaatkan Mesin "Berpikir" (thinkingConfig) 
 

Fitur thinkingConfig adalah kapabilitas khas dari seri Gemini 2.5. Fitur ini memberikan 
kontrol langsung kepada developer atas proses penalaran internal model, 
memungkinkan adanya keseimbangan yang dapat disesuaikan antara kualitas 
respons, biaya, dan latensi.1 

●​ thinkingBudget: 
○​ Fungsi: Parameter ini adalah sebuah bilangan bulat yang menentukan jumlah 

token yang dapat digunakan oleh model untuk proses "berpikir" internalnya 
sebelum menghasilkan jawaban akhir.4 

○​ Rentang untuk 2.5 Pro: 128 hingga 32,768 token.4 

○​ Nilai Khusus: 
■​ -1: Mengaktifkan "pemikiran dinamis" (dynamic thinking). Dalam mode ini, 

model akan secara otomatis menilai kompleksitas tugas dan 
mengalokasikan anggaran berpikir yang sesuai. Ini adalah pengaturan 
default dan direkomendasikan untuk sebagian besar kasus penggunaan 
karena sifatnya yang adaptif.1 

■​ Proses berpikir tidak dapat dinonaktifkan (dengan mengatur 
thinkingBudget=0) untuk Gemini 2.5 Pro, tidak seperti pada model 2.5 
Flash.4 

○​ Implementasi Kode: Berikut adalah contoh cara mengatur thinkingBudget 



dalam Python dan REST. 
■​ Python SDK:​

Python​
from google.generativeai import types​
​
response = model.generate_content(​
    "Selesaikan masalah matematika yang kompleks ini...",​
    generation_config=types.GenerateContentConfig(​
        thinking_config=types.ThinkingConfig(thinking_budget=16384)​
    )​
)​
​
4 

■​ REST API:​
JSON​
{​
  "contents": [...],​
  "generationConfig": {​
    "thinkingConfig": {​
      "thinkingBudget": 16384​
    }​
  }​
}​
​
4 

●​ include_thoughts: 
○​ Fungsi: Parameter boolean ini, jika diatur ke true, akan menginstruksikan API 

untuk mengembalikan ringkasan yang disintesis dari proses penalaran internal 
model bersama dengan jawaban akhir.4 

○​ Kasus Penggunaan: Ini adalah alat yang sangat berharga untuk debugging 
dan iterasi prompt. Dengan memeriksa "ringkasan pemikiran" (thought 
summary), developer dapat memahami mengapa model menghasilkan output 
tertentu, mengidentifikasi logika yang salah, dan menyempurnakan prompt 
atau parameter untuk mendapatkan hasil yang lebih baik.4 

Pengenalan thinkingBudget secara efektif mengeksternalkan trilema rekayasa inti 
dalam penerapan LLM: kualitas, biaya, dan latensi. Developer kini memiliki tanggung 
jawab eksplisit untuk menyeimbangkan ketiga faktor ini. Anggaran yang lebih tinggi 
umumnya menghasilkan penalaran yang lebih mendalam dan respons yang lebih 
berkualitas, namun dengan konsekuensi peningkatan penggunaan token (biaya) dan 



waktu pemrosesan (latensi).4 Penelitian pada masalah yang sangat kompleks, seperti 
soal olimpiade matematika, menunjukkan bahwa bahkan anggaran maksimum 32,768 
token mungkin tidak cukup, yang menggarisbawahi adanya batasan.33 Oleh karena itu, 
pendekatan "atur dan lupakan" tidaklah optimal. Sistem produksi harus menerapkan 
strategi alokasi anggaran yang cerdas, mungkin dengan sistem berjenjang: kueri 
sederhana menggunakan anggaran tetap yang rendah untuk kecepatan dan efisiensi 
biaya, sementara kueri yang kompleks dan bernilai tinggi dialihkan ke pemikiran 
dinamis ( 

-1) atau anggaran tetap yang tinggi, dengan menerima biaya dan latensi yang lebih 
besar demi hasil yang superior.34 

 

2.3. Memastikan Output yang Bertanggung Jawab (safetySettings) 
 

Gemini API dilengkapi dengan filter keamanan bawaan untuk mencegah konten 
berbahaya. Filter ini dapat dikonfigurasi untuk menyeimbangkan antara keamanan dan 
kebebasan berekspresi sesuai kebutuhan aplikasi.19 

●​ Kategori Bahaya: Terdapat empat kategori utama yang dipantau: 
HARM_CATEGORY_HARASSMENT (pelecehan), HARM_CATEGORY_HATE_SPEECH 
(ujaran kebencian), HARM_CATEGORY_SEXUALLY_EXPLICIT (konten seksual 
eksplisit), dan HARM_CATEGORY_DANGEROUS_CONTENT (konten berbahaya).19 

●​ Ambang Batas Blokir: Developer dapat mengatur ambang batas blokir untuk 
setiap kategori. Pilihan yang tersedia berkisar dari BLOCK_NONE (tidak memblokir 
apa pun) hingga BLOCK_LOW_AND_ABOVE (memblokir konten dengan 
probabilitas rendah, sedang, atau tinggi untuk dianggap berbahaya). Pengaturan 
default adalah memblokir konten dengan probabilitas MEDIUM atau lebih tinggi.19 

●​ Konfigurasi: Pengaturan keamanan khusus dapat diterapkan dengan 
mengirimkan daftar objek SafetySetting dalam permintaan API, yang akan 
menimpa pengaturan default.​
Python​
from google.generativeai import types​
​
safety_settings =​
​
response = model.generate_content("...", safety_settings=safety_settings)​
​



19 

●​ Penanganan Respons: Jika sebuah respons diblokir karena alasan keamanan, 
bidang finish_reason dalam objek respons akan berisi nilai SAFETY. Developer 
kemudian dapat memeriksa objek safetyRatings untuk mendapatkan detail 
tentang kategori mana yang terpicu dan pada tingkat probabilitas apa.19 

 

Bagian III: Kerangka Kerja Sistematis untuk Rekayasa Prompt 
Tingkat Lanjut 
 
Setelah menguasai parameter API, fokus beralih ke seni dan ilmu merancang konten 
prompt itu sendiri. Bagian ini menyajikan kerangka kerja yang sistematis, dimulai dari 
prinsip-prinsip dasar hingga pola-pola agentik yang kompleks untuk membuka 
potensi penuh Gemini 2.5 Pro. 

 

3.1. Prinsip-Prinsip Desain Prompt yang Efektif 
 

Fondasi dari setiap interaksi yang sukses dengan model bahasa adalah prompt yang 
dirancang dengan baik. Prinsip-prinsip berikut merupakan pilar untuk mendapatkan 
respons yang akurat, relevan, dan terstruktur. 
●​ Kejelasan dan Spesifisitas: Ini adalah prinsip yang paling fundamental. Berikan 

instruksi yang jelas, tidak ambigu, dan terperinci. Untuk permintaan yang 
kompleks, pecah tugas menjadi langkah-langkah logis yang dapat diikuti oleh 
model.22 Hindari bahasa yang samar-samar yang dapat ditafsirkan secara ganda. 

●​ Penetapan Persona dan Peran: Salah satu teknik yang paling efektif untuk 
meningkatkan kualitas respons adalah dengan menetapkan peran atau persona 
untuk model. Hal ini dapat dilakukan melalui system_instruction atau dengan 
memulai prompt dengan frasa seperti, "Anda adalah seorang arsitek keamanan 
siber ahli...".24 Menetapkan peran akan membingkai respons model dalam konteks 
keahlian tertentu, menghasilkan jawaban yang lebih mendalam dan relevan 
dengan domain tersebut. 

●​ Few-Shot Prompting: Alih-alih hanya memberikan instruksi, berikan 2-3 contoh 
(few-shot) dari format input-output yang diinginkan langsung di dalam prompt. Ini 
adalah cara yang sangat ampuh untuk memandu format, gaya, dan bahkan pola 



penalaran model. Secara umum, prompt yang menyertakan contoh cenderung 
menghasilkan output yang jauh lebih konsisten dan akurat dibandingkan dengan 
prompt tanpa contoh (zero-shot).22 

●​ Output Terstruktur: Untuk kasus penggunaan di mana output model akan 
diproses secara programatik, sangat penting untuk secara eksplisit meminta 
format output tertentu seperti JSON atau Markdown. Untuk JSON, Gemini API 
menyediakan mekanisme yang kuat melalui parameter response_mime_type: 
'application/json' yang dikombinasikan dengan response_schema. Dengan 
menyediakan skema JSON, developer dapat memaksa model untuk menghasilkan 
output yang sesuai dengan struktur data yang telah ditentukan, yang secara 
dramatis mengurangi kebutuhan untuk parsing dan validasi pasca-pemrosesan.37 

 

3.2. Kerangka Kerja Penalaran Tingkat Lanjut 
 

Dengan kemampuan berpikir natif Gemini 2.5 Pro, pendekatan terhadap penalaran 
telah berevolusi. Developer kini dapat memanfaatkan kerangka kerja yang lebih 
canggih untuk memecahkan masalah yang kompleks. 
●​ Chain-of-Thought (CoT) dan Evolusinya: 

○​ CoT Manual: Meskipun Gemini 2.5 Pro memiliki kemampuan berpikir internal, 
teknik CoT manual (misalnya, menambahkan instruksi seperti "Mari kita 
pikirkan langkah demi langkah") masih bisa berguna, terutama sebagai teknik 
debugging atau untuk model yang lebih sederhana.39 

○​ Chain-of-Draft (CoD): Sebagai evolusi yang lebih efisien dari CoT, CoD 
menginstruksikan model untuk menghasilkan wawasan kritis yang ringkas di 
setiap langkah penalaran, alih-alih penjelasan yang panjang lebar. Pendekatan 
minimalis ini secara signifikan mengurangi penggunaan token dan latensi 
sambil mempertahankan atau bahkan meningkatkan akurasi. Implementasi 
dengan Gemini dapat dilakukan dengan memberikan instruksi sistem untuk 
"hanya menyimpan draf minimum untuk setiap langkah berpikir".41 

○​ Meskipun CoT manual adalah teknik yang kuat, penggunaannya pada model 
dengan kemampuan penalaran natif seperti Gemini 2.5 Pro memerlukan 
pertimbangan. Model ini sudah dirancang untuk melakukan penalaran 
internal.3 Beberapa penelitian menunjukkan bahwa memaksakan​
prompt CoT eksplisit pada model yang sudah dilatih untuk berpikir secara 
natif terkadang dapat mengganggu kemampuannya dalam mengikuti 
instruksi.43 Oleh karena itu, praktik terbaik untuk 2.5 Pro sering kali bukan lagi 



menggunakan frasa CoT manual, melainkan mengontrol​
kedalaman penalaran natifnya melalui thinkingBudget. 

●​ ReAct (Reason+Act) untuk Perilaku Agentik: 
○​ Konsep: Kerangka kerja ReAct memungkinkan model untuk berinteraksi 

dengan dunia luar. Model secara berulang-ulang melakukan siklus: Reason 
(berpikir tentang langkah selanjutnya), Act (mengambil tindakan dengan 
memanggil alat eksternal), dan Observe (mengamati hasil dari tindakan 
tersebut untuk menginformasikan langkah berpikir berikutnya).44 

○​ Implementasi dengan Gemini: Pola ReAct diimplementasikan secara native 
di Gemini melalui parameter tools dan toolConfig. Developer mendeklarasikan 
alat (fungsi) yang tersedia, dan model, dalam langkah penalarannya, akan 
memutuskan fungsi mana yang akan dipanggil. API kemudian mengeksekusi 
fungsi tersebut, dan developer bertanggung jawab untuk memberikan 
hasilnya kembali ke model pada giliran percakapan berikutnya untuk 
menyelesaikan siklus observasi.44 

○​ Contoh dengan LangGraph: Kerangka kerja seperti LangGraph menyediakan 
cara terstruktur untuk membangun agen ReAct. LangGraph memodelkan alur 
kerja sebagai sebuah grafik, di mana developer mendefinisikan nodes (untuk 
memanggil model atau alat) dan edges (untuk menentukan alur logika 
berdasarkan keadaan saat ini). Ini menyederhanakan pengelolaan status 
(seperti riwayat pesan) dan logika perulangan yang diperlukan untuk agen 
ReAct.44 

 

3.3. Mengelola Kompleksitas untuk Tugas Skala Besar 
 

Untuk tugas-tugas yang melampaui lingkup satu prompt tunggal, strategi dekomposisi 
dan orkestrasi menjadi sangat penting. 
●​ Prompt Chaining: Untuk alur kerja yang memiliki beberapa langkah sekuensial 

yang jelas, gunakan teknik prompt chaining. Output dari satu panggilan API 
menjadi input untuk panggilan berikutnya. Ini sangat efektif untuk tugas-tugas 
seperti analisis data multi-tahap, di mana langkah pertama adalah pembersihan 
data, diikuti oleh analisis statistik, dan diakhiri dengan pembuatan laporan.22 

●​ Dekomposisi: Untuk tugas yang sangat besar dan kompleks, seperti merefaktor 
seluruh basis kode atau menganalisis dokumen setebal ribuan halaman, 
dekomposisi adalah kuncinya. Alih-alih meminta model untuk "memperbarui 
seluruh aplikasi," pecah permintaan menjadi unit-unit yang lebih kecil dan dapat 



dikelola: "analisis fungsi spesifik ini," "refaktor modul ini," lalu "integrasikan 
perubahan tersebut." Pendekatan ini tidak hanya menghindari batas token output 
tetapi juga membuat proses debugging menjadi jauh lebih mudah dan 
terkontrol.47 

●​ Agregasi Respons: Untuk tugas yang dapat diparalelkan (misalnya, meringkas 
banyak artikel berita secara independen), kirim beberapa permintaan API secara 
bersamaan untuk memproses bagian-bagian data yang berbeda. Setelah semua 
respons diterima, agregasikan hasilnya dalam logika aplikasi Anda untuk 
menghasilkan output akhir yang komprehensif.22 

 

Bagian IV: Implementasi Praktis dan Kasus Penggunaan dari 
Gemini Cookbook 
 
Untuk menjembatani konsep teoretis dengan aplikasi dunia nyata, bagian ini akan 
menyoroti contoh-contoh praktis yang diambil dari sumber daya resmi Google, 
khususnya Gemini API Cookbook. Contoh-contoh ini menunjukkan bagaimana 
fitur-fitur inti Gemini 2.5 Pro dapat dimanfaatkan untuk membangun aplikasi yang 
canggih. 

 

4.1. Penguasaan Multimodal 
 

Salah satu keunggulan utama Gemini 2.5 Pro adalah kemampuannya yang bersifat 
multimodal secara natif. Ini berarti model dapat memproses dan melakukan penalaran 
lintas berbagai jenis data—teks, kode, gambar, audio, dan video—dalam satu prompt 
yang sama, membuka kemungkinan aplikasi yang sebelumnya tidak praktis.1 

●​ Contoh dari Cookbook: 
○​ Gambar & Teks: Contoh "Tebak bentuk" (Guess the shape) dari Cookbook 

menunjukkan bagaimana beberapa gambar dapat disertakan dalam satu 
prompt untuk tugas penalaran visual.49 

○​ Video & Teks: Model ini mampu menganalisis konten video (sekitar 45 menit 
dengan audio, atau 1 jam tanpa audio) untuk menghasilkan ringkasan, 
transkripsi, atau bahkan spesifikasi aplikasi berdasarkan demonstrasi dalam 
video.10 



○​ Analisis Basis Kode: Dengan memanfaatkan jendela konteks yang besar, 
developer dapat mengunggah seluruh proyek dalam format arsip ZIP. Model 
kemudian dapat menganalisis dependensi, menyarankan perbaikan bug, atau 
mengoptimalkan logika di seluruh basis kode.10 

○​ Referensi Resmi: Gemini API Cookbook di GitHub adalah sumber daya utama 
dan sangat direkomendasikan untuk tutorial langsung dan contoh praktis yang 
mencakup berbagai fitur.12 

 

4.2. Membangun Alur Kerja Agentik dengan Alat 
 

Kemampuan untuk berinteraksi dengan sistem eksternal adalah inti dari alur kerja 
agentik. Gemini 2.5 Pro menyediakan dua mekanisme utama untuk ini: function calling 
dan code execution. 
●​ Function Calling: Fitur ini memungkinkan Gemini untuk terhubung dengan alat 

dan API eksternal. Developer mendeklarasikan fungsi yang tersedia menggunakan 
parameter tools, lengkap dengan nama, deskripsi, dan skema parameter. Model 
kemudian secara cerdas akan menentukan kapan dan bagaimana memanggil 
fungsi-fungsi ini untuk menyelesaikan permintaan pengguna.1 

●​ Code Execution: Gemini 2.5 Pro memiliki alat eksekusi kode bawaan yang 
memungkinkannya untuk menghasilkan dan menjalankan kode Python secara 
internal. Ini sangat kuat untuk tugas-tugas yang memerlukan perhitungan 
matematis yang tepat, analisis data, atau pembuatan visualisasi. Meskipun masih 
dalam tahap eksperimental, fitur ini membuka pintu untuk penalaran berbasis 
kode yang canggih.6 

●​ Grounding: Untuk meningkatkan akurasi faktual dan mengurangi halusinasi, 
Gemini dapat diinstruksikan untuk "mendasarkan" (grounding) jawabannya pada 
informasi dari sumber eksternal. Kemampuan Grounding with Google Search 
memungkinkan model untuk terhubung dengan data dunia nyata dari Google 
Search, memastikan bahwa responsnya relevan dan terkini.6 

 

4.3. Memanfaatkan Jendela Konteks 1 Juta Token 
 

Gemini 2.5 Pro dilengkapi dengan jendela konteks input sebesar 1 juta token (dengan 



rencana perluasan hingga 2 juta), yang memungkinkannya untuk memproses dan 
melakukan penalaran atas volume data yang sangat besar dalam satu permintaan 
tunggal.1 

●​ Kasus Penggunaan: 
○​ Analisis Dokumen: Meringkas, menanyakan, dan mengekstrak wawasan dari 

seluruh buku, laporan keuangan yang panjang, atau kumpulan makalah 
penelitian dalam satu kali proses.48 

○​ Pemahaman Basis Kode: Memberikan seluruh repositori kode sebagai 
konteks untuk tugas-tugas seperti debugging kompleks, refaktorisasi skala 
besar, atau pembuatan dokumentasi teknis yang komprehensif.5 

○​ Pemahaman Video: Menganalisis konten video berdurasi panjang (hingga 3 
jam menurut laporan teknis) untuk peringkasan, deteksi peristiwa, atau 
pembuatan konten turunan.5 

●​ Praktik Terbaik: Untuk memaksimalkan utilitas jendela konteks yang besar sambil 
mengoptimalkan biaya, developer dapat memanfaatkan fitur seperti context 
caching. Dengan menyimpan data yang sering digunakan dalam cache, panggilan 
API berikutnya yang menggunakan konteks yang sama akan mendapatkan diskon 
token yang signifikan, mengurangi latensi dan biaya.6 

 

Bagian V: Jaminan Kualitas, Pemecahan Masalah, dan 
Optimalisasi 
 
Bekerja dengan model yang canggih seperti Gemini 2.5 Pro juga menghadirkan 
tantangan praktis. Bagian terakhir ini membahas strategi untuk memastikan 
keandalan, melakukan debugging secara efektif, dan mengatasi masalah umum yang 
mungkin dihadapi saat berinteraksi dengan API. 

 

5.1. Menavigasi dan Memitigasi Masalah Kualitas Respons 
 

Penting untuk diakui bahwa terdapat laporan signifikan dari komunitas mengenai 
regresi dalam kualitas respons untuk rilis publik Gemini 2.5 Pro dibandingkan dengan 
versi pratinjau sebelumnya.54 Memahami mode kegagalan umum adalah langkah 
pertama untuk membangun aplikasi yang tangguh. 



●​ Mode Kegagalan Umum: 
○​ Halusinasi/Fabrikasi: Model dengan percaya diri menciptakan informasi yang 

tidak ada, seperti endpoint API, kutipan penelitian, atau fakta historis.54 

○​ Pengabaian Konteks: Dalam percakapan multi-giliran, model sering kali 
"melupakan" instruksi awal, batasan, atau konteks yang telah ditetapkan 
sebelumnya.54 

○​ Pemotongan Respons: Output berhenti secara tiba-tiba di tengah kalimat, 
terutama untuk konten berformat panjang seperti blok kode atau artikel.54 

○​ Penurunan Kepatuhan Instruksi: Model mengabaikan batasan eksplisit atau 
instruksi pemformatan yang diberikan dalam prompt.55 

●​ Strategi Mitigasi dan Defensive Prompting: 
○​ Alur Kerja Verifikasi: Untuk klaim faktual, terapkan pola ReAct di mana model 

diinstruksikan untuk memverifikasi informasinya sendiri menggunakan alat 
pencarian sebelum menyajikan jawaban akhir. Ini membangun lapisan 
pemeriksaan fakta ke dalam proses generasi.33 

○​ Instruksi Sistem yang Ketat: Untuk tugas yang sensitif seperti debugging 
kode, gunakan system_instruction yang sangat ketat. Secara eksplisit larang 
model untuk melakukan refaktorisasi, penggantian nama, atau "perbaikan" 
kode yang tidak diminta. Paksa model untuk hanya membuat perubahan 
minimal yang diperlukan untuk memperbaiki bug.58 

○​ Generasi Iteratif: Untuk konten berformat panjang, pecah tugas menjadi 
bagian-bagian yang lebih kecil. Minta kerangka terlebih dahulu, kemudian 
hasilkan konten per bagian. Jika terjadi pemotongan, salin blok lengkap 
terakhir dan minta model untuk melanjutkan dari titik tersebut dalam prompt 
baru.47 

○​ Manajemen Status Eksternal: Untuk aplikasi multi-giliran, jangan hanya 
mengandalkan memori internal model. Simpan batasan kritis dan konteks 
penting dalam status aplikasi Anda dan suntikkan kembali ke dalam prompt 
pada setiap giliran untuk memperkuat instruksi. 

 

5.2. Panduan Developer untuk Penanganan Kesalahan API 
 

Diagnosis dan penyelesaian kesalahan API yang umum adalah keterampilan penting 
bagi setiap developer. Tabel berikut merangkum kode kesalahan HTTP yang paling 
sering ditemui beserta penyebab umum dan tindakan yang direkomendasikan. 



Tabel 2: Kode Kesalahan API Umum dan Resolusinya 

 
Kode HTTP Status Penyebab Umum Tindakan yang 

Direkomendasikan 

400 INVALID_ARGUMENT Badan permintaan Periksa kembali 
tidak diformat dokumentasi API 
dengan benar; nilai untuk format 
parameter di luar permintaan yang 
rentang yang valid; benar. Pastikan 
penggunaan fitur semua nilai 
pratinjau dengan parameter (misalnya, 
endpoint stabil. temperature, 

candidateCount) 
berada dalam batas 
yang ditentukan.32 

403 PERMISSION_DENIED Kunci API tidak valid, Verifikasi bahwa 
kedaluwarsa, atau Kunci API sudah 
tidak memiliki izin benar dan aktif di 
yang diperlukan Google AI Studio atau 
untuk model atau konsol Google Cloud. 
proyek yang diminta. Pastikan API yang 

relevan diaktifkan 
untuk proyek Anda.32 

404 NOT_FOUND Nama model yang Pastikan Anda 
diminta salah atau menggunakan 
tidak ada. URI untuk pengidentifikasi 
file media (misalnya, model yang benar 
gambar, video) tidak dan lengkap 
valid atau tidak dapat (misalnya, 
diakses. gemini-2.5-pro). 

Periksa kembali 
semua URI sumber 
daya eksternal.32 

429 RESOURCE_EXHAUST Melebihi batas laju Terapkan strategi 
ED permintaan exponential backoff 

(misalnya, untuk mencoba 
permintaan per kembali permintaan 
menit) untuk tingkat secara otomatis 
API Anda (gratis atau setelah jeda. Jika 
berbayar). sering terjadi, 



pertimbangkan untuk 
meningkatkan kuota 
Anda.32 

500 INTERNAL Terjadi kesalahan tak Coba kurangi ukuran 
terduga di sisi server prompt atau konteks 
Google. Sering kali Anda. Coba lagi 
disebabkan oleh setelah beberapa 
konteks input yang saat. Jika masalah 
terlalu panjang atau berlanjut, laporkan 
kompleks. melalui saluran 

umpan balik resmi.32 

503 UNAVAILABLE Layanan untuk Tunggu sebentar dan 
sementara kelebihan coba lagi permintaan 
beban atau tidak Anda. Sebagai solusi 
tersedia. Kapasitas sementara, coba 
untuk model yang beralih ke model lain 
diminta sedang yang kurang padat 
penuh. (misalnya, dari 2.5 

Pro ke 2.5 Flash).32 

 

5.3. Rekomendasi Akhir dan Pandangan ke Depan 
 

Untuk memaksimalkan efektivitas Gemini 2.5 Pro, developer harus mengadopsi 
pendekatan yang strategis dan berlapis. Praktik terbaik yang paling krusial meliputi: 
memanfaatkan kemampuan berpikir natif melalui thinkingBudget daripada 
mengandalkan CoT manual; menggunakan instruksi sistem yang ketat untuk 
mengontrol perilaku dalam tugas-tugas yang sensitif; memecah masalah kompleks 
menjadi tugas-tugas yang lebih kecil dan dapat dikelola; dan membangun lapisan 
verifikasi, terutama untuk aplikasi yang membutuhkan akurasi faktual yang tinggi. 

Evolusi model ini jelas mengarah pada sistem yang lebih agentik, di mana model tidak 
hanya merespons tetapi juga secara proaktif mengambil tindakan untuk mencapai 
tujuan. Kerangka kerja seperti LangGraph akan menjadi semakin penting untuk 
mengelola kompleksitas alur kerja agentik ini. Selain itu, pengenalan mode 
eksperimental seperti "Deep Think" memberikan gambaran sekilas tentang masa 
depan kemampuan penalaran yang lebih kuat lagi, yang mampu menangani masalah 
yang saat ini berada di luar jangkauan model yang ada.61 



Untuk tetap menjadi yang terdepan, developer harus terus memantau sumber daya 
penting. Ini termasuk dokumentasi resmi Gemini API sebagai sumber kebenaran 
utama 15, Gemini API Cookbook di GitHub untuk contoh-contoh praktis dan kode yang 
dapat digunakan kembali 12, dan Forum Developer Google AI sebagai tempat untuk 
berdiskusi, melaporkan masalah, dan belajar dari komunitas.50 Dengan 
menggabungkan pemahaman teknis yang mendalam tentang API dengan strategi 
rekayasa 

prompt yang canggih, developer dapat membuka potensi penuh dari Gemini 2.5 Pro 
untuk membangun generasi baru aplikasi cerdas.